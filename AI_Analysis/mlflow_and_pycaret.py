#mlflowã¨ã¯ã€æ©Ÿæ¢°å­¦ç¿’ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«(å‰å‡¦ç†â†’å­¦ç¿’â†’ãƒ‡ãƒ—ãƒ­ã‚¤)ã‚’ç®¡ç†ã™ã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãªãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
#Tracking: ãƒ­ã‚®ãƒ³ã‚°
#ãƒ­ã‚®ãƒ³ã‚°ï¼ˆè‹±ï¼šloggingï¼‰ã¨ã¯
#ã€Œå–ã‚‹ãœå–ã‚‹ãœï½ãƒ­ã‚°å–ã‚‹ãœï½ã€ã®ã“ã¨ã€‚
#å®Ÿéš›ã«ãƒ­ã‚®ãƒ³ã‚°ã‚’è¡Œã£ã¦ã¿ã‚‹ â˜›ã€€pycaret ã®å¾Œã«å®Ÿæ–½
#mlflow is an open source platform to manage the machine learning lifecycle (preprocessing -> training -> deployment)
#Tracking: Logging
#Logging (English: logging) means.
#"Take it, take it, take it - log it.
#Actual logging â˜› Performed after pycaret

mlflow.set_tracking_uri('./hoge/mlruns/')

# experimentãŒå­˜åœ¨ã—ãªã‘ã‚Œã°ä½œæˆã•ã‚Œã‚‹ã€‚
mlflow.set_experiment('compare_max_depth')

import pandas as pd
import itertools
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
sns.set() 
%matplotlib inline
import codecs
import os
import codecs
import datetime
from sklearn.model_selection import train_test_split

class my_directory_p:
    def __init__(self,pass_out):
        #self.day_im = day_im
        self.pass_out = pass_out


    def pass_o(self):
        return self.pass_out

    def pass_out_new(self):
        # ãƒ•ã‚©ãƒ«ãƒ€ã€Œoutputã€ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆã™ã‚‹
        data_dir = self.pass_out
        if not os.path.exists(data_dir):
            os.mkdir(data_dir)
        print(u.pass_o()+"ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆã—ã¾ã—ãŸï¼ï¼")
        
    def imp_data(self):
        #ubuntu 
        image_file_path = './data/"data_name".csv'

        import pandas as pd

        with codecs.open(image_file_path, "r", "Shift-JIS", "ignore") as file:
                df_r9 = pd.read_table(file, delimiter=",")

        return df_r9
        
#ã“ã“ã§selfã®å€¤ã‚’å®šç¾©ã™ã‚‹
u = my_directory_p("./20210201_output/")
u.pass_out_new()
df_r=u.imp_data()

u.pass_o()

#----------------------

#data predect ãƒ‡ãƒ¼ã‚¿ã‚’pandasã§æº–å‚™ã™ã‚‹

#----------------------
#mlflowã¨ã¯ã€æ©Ÿæ¢°å­¦ç¿’ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«(å‰å‡¦ç†â†’å­¦ç¿’â†’ãƒ‡ãƒ—ãƒ­ã‚¤)ã‚’ç®¡ç†ã™ã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãªãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
#Tracking: ãƒ­ã‚®ãƒ³ã‚°
#ãƒ­ã‚®ãƒ³ã‚°ï¼ˆè‹±ï¼šloggingï¼‰ã¨ã¯

#ã€Œå–ã‚‹ãœå–ã‚‹ãœï½ãƒ­ã‚°å–ã‚‹ãœï½ã€ã®ã“ã¨ã€‚
#å®Ÿéš›ã«ãƒ­ã‚®ãƒ³ã‚°ã‚’è¡Œã£ã¦ã¿ã‚‹ â˜›ã€€pycaret ã®å¾Œã«å®Ÿæ–½
with mlflow.start_run():
    mlflow.log_param('param1', 1) # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    mlflow.log_metric('metric1', 0.1) # ã‚¹ã‚³ã‚¢
    mlflow.log_artifact(filename) # ãã®ä»–ã€ãƒ¢ãƒ‡ãƒ«ã‚„ãƒ‡ãƒ¼ã‚¿ãªã©
mlflow.search_runs() # experimentå†…ã®ãƒ­ã‚®ãƒ³ã‚°å†…å®¹ã‚’å–å¾—ã§ãã‚‹

#------------------------------

#anaconda prompt ã‚’é–‹ãã€€Open the anaconda prompt

#URIã§è¨­å®šã—ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¾ã§ç§»å‹•ã™ã‚‹ã€‚ 
#ã“ã®æ™‚ã€ mlruns ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒé…ä¸‹ã«ãªã‚‹ã‚ˆã†ã«ã™ã‚‹( mlruns ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã€ mlruns ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒä½œæˆã•ã‚Œã‚‹)ã€‚ 
#mlflow ui ã§ãƒ­ãƒ¼ã‚«ãƒ«ã‚µãƒ¼ãƒãŒèµ·å‹•ã™ã‚‹ã€‚

#Go to the directory set in URI. 
#Move to the directory set in the URI. At this time, make sure that the mlruns directory is under it (if the mlruns directory does not exist, the mlruns directory is created). 
#The local server is started by mlflow ui.


#ğ‘ğ‘‘./â„ğ‘œğ‘”ğ‘’/  ls mlruns
$ mlflow ui
#------------------------------

#ãƒ–ãƒ©ã‚¦ã‚¶ä¸Šã§ http://127.0.0.1:5000 ã‚’é–‹ã
#------------------------------

tracking = mlflow.tracking.MlflowClient()
experiment = tracking.get_experiment_by_name('hoge')

#pycaret and mlflow  https://pycaret.org/mlflow/

# tracking uri 
import mlflow 
mlflow.set_tracking_uri('./hoge/mlruns/')

from pycaret.regression import *
exp_name = setup(df_all, target = 'target',train_size = 0.99,silent=True,fold_strategy='timeseries',data_split_shuffle=False, log_experiment = True, experiment_name = 'diabetes1')
best = compare_models()

omp= create_model("lightgbm")
#plot_model(omp)
evaluate_model(omp)

omp= create_model("lightgbm",fold = 5)
evaluate_model(omp)
pred_unseen = predict_model(omp)
pred_unseen
pred_unseen.to_csv(r""+u.pass_o()+'lightgbm_test7_top10_data.csv', encoding = 'shift-jis')
omp= create_model("lightgbm",cross_validation=False)
#evaluate_model(omp)
tuned_lr = tune_model(omp)
evaluate_model(tuned_lr)
pred_unseen = predict_model(tuned_lr)
pred_unseen
pred_unseen.to_csv(r""+u.pass_o()+'lightgbm_tuned_test7_top10_data.csv', encoding = 'shift-jis')
